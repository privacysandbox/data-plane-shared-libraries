#!/bin/bash
# Copyright 2023 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Run benchmarks
set -o errexit
set -o pipefail

function usage() {
  local -r -i exitval=${1-1}
  cat &>/dev/stderr <<USAGE
usage:
  ${BASH_SOURCE[0]} <options>
    --verbose                       Enable xtrace verbose output
    --target <name>                 Name of a benchmark target to run. Can be specified multiple times.
    --benchmark_time_unit={ns|us|ms|s}
    --benchmark_list_tests={true|false}
    --benchmark_filter=<regex>
    --benchmark_min_time=<integer>x OR <float>s
    --benchmark_min_warmup_time=<min_warmup_time>
    --benchmark_repetitions=<num_repetitions>
    --benchmark_enable_random_interleaving={true|false}
    --benchmark_report_aggregates_only={true|false}
    --benchmark_display_aggregates_only={true|false}
    --benchmark_format=<console|json|csv>
    --benchmark_out=<filename>
    --benchmark_out_format=<json|console|csv>  default: json
    --benchmark_color={auto|true|false}
    --benchmark_counters_tabular={true|false}  default: true
    --benchmark_context=<key>=<value>,...

environment variables (all optional):
    WORKSPACE                    Set the path to the workspace (repo root)
USAGE
  # shellcheck disable=SC2086
  exit ${exitval}
}

SCRIPT_DIR="$(dirname "$(readlink -f "${BASH_SOURCE[0]}")")"
readonly SCRIPT_DIR
readonly TOOLS_DIR="${SCRIPT_DIR}"/../builders/tools
# shellcheck disable=SC1090
source "${TOOLS_DIR}"/builder.sh

declare -a targets
declare -a benchmark_args=(
  "--benchmark_out_format=json"
  "--benchmark_counters_tabular=true"
)

while [[ $# -gt 0 ]]; do
  case "$1" in
    --verbose)
      VERBOSE=1
      shift
      ;;
    --target)
      targets+=("$2")
      shift 2 || usage
      ;;
    --benchmark_*)
      benchmark_args+=("$1")
      shift
      ;;
    -h | --help) usage 0 ;;
    *) usage ;;
  esac
done

if [[ ${VERBOSE} -eq 1 ]]; then
  set -o xtrace
fi

# TODO: b/326459539 - Normalize benchmark target names
# JSON output files for each benchmark and the metrics that're in perfgate are
# named after the build target, so changing the build target will lose history
# if not preserved. To remedy this, add a map from "json_file_names" to
# "perfgate_benchmark_name" in https://source.corp.google.com/piper///depot/google3/chrome/privacy_sandbox/kiwi_air_force/perfgate/backfill_placer_data.sh;l=44.
# IMPORTANT: When changing target names, please change all other occurrences.
if [[ ${#targets[@]} -eq 0 ]]; then
  targets+=(
    //src/aws/proxy:benchmark_test
    //src/core/common/uuid:uuid_benchmark
    //src/roma/benchmark:ba_server_benchmark
    //src/roma/benchmark:isolate_restoration_benchmark
    //src/roma/benchmark:host_api_grpc_benchmark
    //src/roma/benchmark:kv_server_udf_benchmark_test
    //src/roma/benchmark:roma_v8_prime_sieve_benchmark
    //src/roma/benchmark:roma_v8_sort_list_benchmark
    //src/roma/benchmark/serde:serialize_benchmark
    //src/roma/benchmark/serde:deserialize_benchmark
    //src/roma/benchmark/compiler:execute_benchmark
    //src/roma/benchmark/compiler:load_benchmark
    //src/roma/config:type_converter_benchmark
    //src/roma/sandbox/dispatcher:dispatcher_benchmark
    //src/roma/sandbox/js_engine/v8_engine:arraybuffer_benchmark
    //src/roma/sandbox/worker_api/sapi:worker_wrapper_impl_benchmark
    # TODO: Enable logging benchmark after reducing volume of log output.
    # //src/roma/benchmark:logging_benchmark
    # TODO: b/303250465 - Turn this back on once the segfault is fixed.
    # //src/roma/benchmark:benchmark_suite_test
  )
fi

mkdir -p "${WORKSPACE}"/dist/benchmarks

for tgt in "${targets[@]}"; do
  label="${tgt#*:}"
  out_fname="${label%_test}".json
  # The logs are noisy from this test so use "grep -Fv" to hide them:
  "${TOOLS_DIR}"/bazel-debian run \
    --config=benchmark \
    "${tgt}" \
    -- \
    --benchmark_out="/src/workspace/dist/benchmarks/${out_fname}" \
    "${benchmark_args[@]}" \
    2>/dev/null \
    | grep -Ev "sandbox.cc|monitor_base.cc|sandbox2.cc"
done

"${TOOLS_DIR}"/normalize-dist
